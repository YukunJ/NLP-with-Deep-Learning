Assignment 4 written part
Yukun Jiang 

1(g). 
	Essentially, in the step function, we manually set the attention score of "padded" to negative infinite, so that the "padded" don't get any attention in the process. And their information won't be passed to generate next step's output
	This is important because, if there are a lot very sentence and a very short sentence in the same batch, the short sentence will have many "padded"s and if we don't manually turn off their attention score, the many "padded" will share and hold a lot of overall attention but they are useless in the overall translation task. 

1(i).
	The BLUE Score is, indeed higher than 21.

1(j).
	Compare multiplicative attention with additive attention, multiplicative attention is faster in computation and space-efficient because of its usage of matrix multiplication. But additive attention might perform better because it balances both the attention at this time step and the current hidden state output.
 
 